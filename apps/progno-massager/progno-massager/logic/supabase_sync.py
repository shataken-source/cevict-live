"""
SUPABASE SYNC - Memory Bridge with Supervisor Gatekeeper
=========================================================
All data passes through SupervisorAgent.authorize_commit() before saving.
"""

import os
import json
from datetime import datetime
from typing import Dict, List, Optional, Any
from dotenv import load_dotenv

load_dotenv()

# Import supervisor and compliance
from .supervisor import (
    get_supervisor, 
    ValidationResult, 
    TriEngineSource,
    LegalDisclaimer
)
from .compliance import PIIProtector

# Supabase client
try:
    from supabase import create_client, Client
    SUPABASE_AVAILABLE = True
except ImportError:
    SUPABASE_AVAILABLE = False
    print("Warning: supabase-py not installed. Running in mock mode.")


class PrognoMemory:
    """
    PROGNO Memory Bridge - Connects to Supabase with Supervisor validation.
    All commits go through the Gatekeeper before hitting the database.
    """
    
    def __init__(self):
        self.supabase: Optional[Client] = None
        self.pii_protector = PIIProtector()
        self.supervisor = get_supervisor()
        self.pending_commits: List[Dict] = []
        self.committed_count = 0
        self.rejected_count = 0
        
        # Initialize Supabase if credentials available
        url = os.environ.get("SUPABASE_URL")
        key = os.environ.get("SUPABASE_KEY")
        
        if SUPABASE_AVAILABLE and url and key:
            try:
                self.supabase = create_client(url, key)
                print("âœ… Supabase connected")
            except Exception as e:
                print(f"âš ï¸ Supabase connection failed: {e}")
                self.supabase = None
        else:
            print("âš ï¸ Running in mock mode (no Supabase credentials)")

    def _prepare_data(self, 
                      event_name: str,
                      score: float,
                      arb_data: Optional[Dict] = None,
                      hedge_data: Optional[Dict] = None,
                      model_version: str = "Cevict Flex 1.0",
                      commands_applied: Optional[List[str]] = None,
                      source: TriEngineSource = TriEngineSource.PROGNO,
                      **kwargs) -> Dict:
        """
        Prepares data for validation and commit.
        """
        # Redact PII from event name
        processed_event_name = self.pii_protector.redact_pii(event_name)
        
        # Process arbitrage and hedge data for PII
        processed_arb = self.pii_protector.process_data_for_pii(arb_data) if arb_data else None
        processed_hedge = self.pii_protector.process_data_for_pii(hedge_data) if hedge_data else None
        
        # Build metadata
        calc_metadata = {
            "arbitrage": processed_arb,
            "hedge": processed_hedge,
            "commands_applied": commands_applied or [],
            "tri_engine_source": source.value
        }
        
        # Build the full record
        data = {
            "event_name": processed_event_name,
            "event_date": kwargs.get('event_date', datetime.now().date().isoformat()),
            "model_version": model_version,
            "probability_score": score,
            "is_arb_found": processed_arb is not None and processed_arb.get("is_arb", False),
            "calc_metadata": calc_metadata,
            "timestamp": datetime.now().isoformat(),
            "actual_result": kwargs.get('actual_result'),
            "was_prediction_correct": kwargs.get('was_prediction_correct')
        }
        
        return data

    def save_outcome(self,
                     event_name: str,
                     score: float,
                     arb_data: Optional[Dict] = None,
                     hedge_data: Optional[Dict] = None,
                     model_version: str = "Cevict Flex 1.0",
                     commands_applied: Optional[List[str]] = None,
                     source: TriEngineSource = TriEngineSource.PROGNO,
                     **kwargs) -> Dict:
        """
        Saves a single prediction outcome with Supervisor validation.
        
        Returns:
            Dict with 'success', 'message', and 'validation' keys
        """
        # Prepare data
        data = self._prepare_data(
            event_name=event_name,
            score=score,
            arb_data=arb_data,
            hedge_data=hedge_data,
            model_version=model_version,
            commands_applied=commands_applied,
            source=source,
            **kwargs
        )
        
        # ðŸ›¡ï¸ SUPERVISOR GATEKEEPER - The critical validation step
        result, message, details = self.supervisor.authorize_commit(data, source)
        
        if result == ValidationResult.REJECTED:
            self.rejected_count += 1
            return {
                'success': False,
                'message': f"Supervisor rejected: {message}",
                'validation': details,
                'data': None
            }
        
        # If approved (even with warnings), commit to database
        if self.supabase:
            try:
                response = self.supabase.table("progno_outcomes").insert(data).execute()
                self.committed_count += 1
                
                return {
                    'success': True,
                    'message': message,
                    'validation': details,
                    'data': response.data[0] if response.data else data
                }
            except Exception as e:
                return {
                    'success': False,
                    'message': f"Database error: {str(e)}",
                    'validation': details,
                    'data': None
                }
        else:
            # Mock mode - still validate but don't persist
            self.committed_count += 1
            return {
                'success': True,
                'message': f"[Mock Mode] {message}",
                'validation': details,
                'data': data
            }

    def save_all_to_supabase(self, 
                             records: List[Dict],
                             source: TriEngineSource = TriEngineSource.PROGNO) -> Dict:
        """
        Batch save with Supervisor validation on EVERY row.
        
        This is the main entry point for bulk data commits.
        Each record goes through authorize_commit() before saving.
        """
        results = {
            'total': len(records),
            'approved': 0,
            'rejected': 0,
            'warnings': 0,
            'details': []
        }
        
        for i, record in enumerate(records):
            # Extract fields from record
            event_name = record.get('event_name', f'Event_{i}')
            score = record.get('probability_score', record.get('score', 0.5))
            
            # Save with validation
            save_result = self.save_outcome(
                event_name=event_name,
                score=score,
                arb_data=record.get('arb_data', record.get('calc_metadata', {}).get('arbitrage')),
                hedge_data=record.get('hedge_data', record.get('calc_metadata', {}).get('hedge')),
                model_version=record.get('model_version', 'Cevict Flex 1.0'),
                commands_applied=record.get('commands_applied', []),
                source=source,
                event_date=record.get('event_date'),
                actual_result=record.get('actual_result'),
                was_prediction_correct=record.get('was_prediction_correct')
            )
            
            # Track results
            if save_result['success']:
                results['approved'] += 1
                if 'warning' in save_result['message'].lower():
                    results['warnings'] += 1
            else:
                results['rejected'] += 1
            
            results['details'].append({
                'index': i,
                'event': event_name,
                'success': save_result['success'],
                'message': save_result['message']
            })
        
        # Log summary
        print(f"\nðŸ“Š Batch Save Complete:")
        print(f"   âœ… Approved: {results['approved']}")
        print(f"   âŒ Rejected: {results['rejected']}")
        print(f"   âš ï¸ Warnings: {results['warnings']}")
        
        return results

    def get_stats(self) -> Dict:
        """
        Returns memory statistics including Supervisor metrics.
        """
        return {
            'committed': self.committed_count,
            'rejected': self.rejected_count,
            'pending': len(self.pending_commits),
            'supervisor_stats': self.supervisor.get_validation_stats(),
            'supabase_connected': self.supabase is not None
        }

    def get_legal_disclaimer(self) -> str:
        """
        Returns the legal disclaimer for exports.
        """
        return LegalDisclaimer.get_export_disclaimer()

    def export_with_disclaimer(self, data: List[Dict], format: str = 'json') -> str:
        """
        Exports data with legal disclaimer header.
        """
        disclaimer = self.get_legal_disclaimer()
        
        if format == 'json':
            export_data = {
                'disclaimer': disclaimer,
                'ai_headers': LegalDisclaimer.get_ai_disclosure_header(),
                'exported_at': datetime.now().isoformat(),
                'record_count': len(data),
                'data': data
            }
            return json.dumps(export_data, indent=2, default=str)
        
        elif format == 'csv':
            import csv
            from io import StringIO
            
            output = StringIO()
            output.write(disclaimer.replace('\n', '\n# '))  # Comment out for CSV
            output.write('\n\n')
            
            if data:
                writer = csv.DictWriter(output, fieldnames=data[0].keys())
                writer.writeheader()
                writer.writerows(data)
            
            return output.getvalue()
        
        else:
            return disclaimer + '\n\n' + str(data)


# Weekly Status Report Generator
class WeeklyReportGenerator:
    """
    Generates the weekly status report for Project Guardian.
    Automatically sent to Victoria every Sunday.
    """
    
    def __init__(self, memory: PrognoMemory):
        self.memory = memory
        self.supervisor = memory.supervisor
    
    def generate_report(self) -> str:
        """
        Generates the weekly status report.
        """
        stats = self.memory.get_stats()
        supervisor_stats = stats['supervisor_stats']
        tri_engine = supervisor_stats.get('tri_engine_stats', {})
        
        report = f"""
================================================================================
                    PROGNO WEEKLY STATUS REPORT
                    Project Guardian | Cevict LLC
================================================================================

Report Generated: {datetime.now().strftime('%A, %B %d, %Y at %I:%M %p')}
Report Period: Last 7 Days

--------------------------------------------------------------------------------
                           EXECUTIVE SUMMARY
--------------------------------------------------------------------------------

Total Predictions Processed: {supervisor_stats.get('total_validations', 0)}
Approval Rate: {supervisor_stats.get('approval_rate', 0)}%

âœ… Approved: {supervisor_stats.get('approvals', 0)}
âŒ Rejected: {supervisor_stats.get('rejections', 0)}

--------------------------------------------------------------------------------
                          TRI-ENGINE CONTRIBUTIONS
--------------------------------------------------------------------------------

This report tracks which AI engine contributed to data processing:

"""
        for engine, data in tri_engine.items():
            if isinstance(data, dict):
                count = data.get('count', 0)
                pct = data.get('percentage', 0)
                bar = 'â–ˆ' * int(pct / 5) + 'â–‘' * (20 - int(pct / 5))
                report += f"  {engine.upper():15} [{bar}] {pct}% ({count} items)\n"
        
        report += f"""
--------------------------------------------------------------------------------
                          ARBITRAGE OPPORTUNITIES
--------------------------------------------------------------------------------

Arbitrage opportunities detected this week: [Calculated from database]
Average profit margin: [Calculated from database]

--------------------------------------------------------------------------------
                          SYSTEM HEALTH
--------------------------------------------------------------------------------

Supabase Connected: {'âœ… Yes' if stats.get('supabase_connected') else 'âŒ No'}
Supervisor Agent: âœ… Active
Gatekeeper Status: âœ… All validations running

--------------------------------------------------------------------------------
                          COMPLIANCE STATUS
--------------------------------------------------------------------------------

âœ… AI Disclosure Headers: Active
âœ… PII Protection: Active  
âœ… Legal Disclaimers: Active
âœ… Alabama Compliance: Verified
âœ… EU AI Act 2025: Compliant

--------------------------------------------------------------------------------
                          NOTES FOR VICTORIA
--------------------------------------------------------------------------------

[Auto-generated notes will appear here based on anomalies detected]

No critical issues this week.

--------------------------------------------------------------------------------

This report was auto-generated by Project Guardian.
For questions, contact the development team.

Â© 2025 Cevict LLC
================================================================================
"""
        return report


# Singleton instance
_memory_instance: Optional[PrognoMemory] = None

def get_memory() -> PrognoMemory:
    global _memory_instance
    if _memory_instance is None:
        _memory_instance = PrognoMemory()
    return _memory_instance
